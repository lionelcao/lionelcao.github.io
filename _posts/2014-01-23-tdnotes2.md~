---
layout: post
title: "Teradata Study Notes-Introduction to the Teradata Database(2)"
description: ""
category: "database"
tags: [teradata, introduction, database]
---
{% include JB/setup %}
注：本文仅作个人学习笔记用，版权为Teradata公司所有，严禁转载。

##Module2 - Relational Database Concepts

  <!-- more -->
###What is a Database?
A database is a collection of permanently stored data that is:

   Logically related - the data relates to other data (tables to tables).
   Shared - many users may access the data.
   Protected - access to data is controlled.
   Managed - the data has integrity and value.

###Logical/Relational Modeling
The Logical Model

    Should be designed without regard to usage
      *Accommodates a wide variety of front end tools
      *Allows the database to be created more quickly
    Should be the same regardless of data volume
    Data is organized according to what it represents - real world business data in table (relational) form
    Includes all the data definitions within the scope of the application or enterprise
    Is generic - the logical model is the template for physical implementation on any RDBMS platform

Normalization

    Process of reducing a complex data structure into a simple, stable one
    Involves removing redundant attributes, keys, and relationships from the conceptual data model

###Relational Databases
Relational databases are solidly founded on Set Theory and are based on the Relational Model.

The key to understanding relational databases is the concept of the table, which is made up of rows and columns.

A column is an attribute of the entity that a table represents.

A row is one instance of all the columns of a table.

###3NF vs. Star Schema Model
A normalized model includes:

    • Entities - One record in a table
    • Attributes - Columns
    • Relationships - between tables

Characteristics of a 3NF Model:

    • The ability to support ad-hoc queries

A Star Schema Model May Include:

    • Facts
    • Dimensions
    • Snowflakes

Characteristics of a Star Schema Model:

    • They tend to have fewer entities
    • They advocate a greater level of denormalization

###Primary Key
Primary Key (PK) values uniquely identify each row in a table.

Primary Key Rules

    • A Primary Key is required for every table.
    • Only one Primary Key is allowed in a table.
    • Primary Keys may consist of one or more columns.
    • Primary Keys cannot have duplicate values (ND).
    • Primary Keys cannot be null (NN).
    • Primary Keys are considered “non-changing” values (NC).

###Foreign Key
Foreign Key (FK) value identifies table relationships.

    • Foreign Keys (FK) are optional.
    • A table may have more than one FK.
    • A FK may consist of more than one column.
    • FK values may be duplicated.
    • FK values may be null.
    • FK values may be changed.
    • FK values must exist elsewhere as a PK (i.e. have referential integrity).

###Relational Advantages
Advantages of a Relational Database compared to other database methodologies include:

    • More flexible than other types
    • Allows businesses to quickly respond to changing conditions
    • Being data-driven vs. application driven
    • Modeling the business, not the processes
    • Makes applications easier to build because the data does more of the work
    • A single copy of the data may serve multiple purposes
    • Supporting trend toward end-user computing
    • Being easy to understand
    • No need to know the access path
    • Solidly founded in set theory

##Module3 - Teradata and the Data Warehouse
###Evolution of Data Processing

    On-line Transaction Processing (OLTP)
    Decision Support Systems (DSS)
    On-line Analytical Processing (OLAP)
    Data Mining (DM)

###Row versus Set Processing
What is Row-by-Row Processing?

    • One row is fetched at a time and all calculations are performed on it.
    • The next row is fetched and processed, and this process continues.
    • A benefit of row processing is that there is less lock contention.

What is Set Processing?

    • Data is processed set-by-set, without a cursor.
    • A single SQL statement completely processes all rows that meet the condition as a set (i.e., to sum all payment rows with 100 or less balances.)
    • With sufficient rows to process, it can be 10 to 30+ or more times faster.

Some Good Uses of Set Processing include:

    • An update with all AMPs involved
    • Single session processing which takes advantage of parallel processing
    • Efficient updates of large amounts of data.

###Response Time versus Throughput
When determining how fast something is, there are two kinds of measures. You can measure how long it takes to do something or you can measure how much gets done per unit time. The former is referred to as response time, access time, transmission time, or execution time depending on the context. The latter is referred to as throughput.

###Response Time
This speed measure is specified by an elapsed time from the initiation of some activity until its completion. The phrase response time is often used in operating systems contexts.

###Throughput
A throughput measure is an amount of something per unit time. For operating systems, throughput is often measured as tasks or transactions per unit time. For storage systems or networks throughput is measured as bytes or bits per unit time. For processors, the number of instructions executed per unit time is an important component of performance.
###What Does this Mean to Teradata?

    Response time measures the average duration of queries and throughput measures quantity of queries completed during a time interval.
    Throughput is a measure of the amount of work processed while response time is a measure of process completion.
    Throughput is how many queries were processed, while response time is how long that processing took.
    Throughput is the number of queries executed in an hour and response time is the elapsed time per query.

In order to improve both response time and throughput on a Teradata system, you could increase CPU power (i.e., add nodes), implement workload management to control resources, and decrease the number of concurrent users.

###The Advantage of Using Detail Data
Until recently, most business decisions were based on summary data.

The problem is that summarized data is not as useful as detail data and cannot answer some questions with accuracy.

With summarized data, peaks and valleys are leveled when the peaks fall at the end of a reporting period and are cut in half—as shown in the example on the facing page.

Here's another example. Think of your monthly bank statement that records checking account activity. If it only told you the total amount of deposits and withdrawals, would you be able to tell if a certain check had cleared? To answer that question you need a list of every check received by your bank. You need detail data.

Decision support—answering business questions—is the real purpose of databases. To answer business questions, decision-makers must have four things:

    The right data
    Enough detail data
    Proper data structure
    Enough computer power to access and produce reports on the data

Strategic workloads tend to rely heavily on detail data.

Consider your own business and how it uses data. Is that data detailed or summarized? If it's summarized, are there questions it cannot answer?

###Data Warehouse Usage Evolution

    Stage 1 - Reporting: What happened?
              Primarily Batch Pre-Defined Reports
    Stage 2 - Analyzing: Why did it happen?
              Increase in Ad Hoc Queries
    Stage 3 - Predicting: What will happen?
              Analytical Modeling Grows
    Stage 4 - Operationalizing: What is happening?
              Continuous Update & Time Sensitive Queries Become Important
    Stage 5 - Active Warehousing: Make it happen!
              Event Based Triggering Takes Hold

###Active Enterprise Intelligence
Active Enterprise Intelligence is the seamless integration of the ADW into the customer’s existing business and technical architectures.

Active Enterprise Intelligence (AEI) is a business strategy for providing strategic and operational intelligence to back office and front line users from a single enterprise data warehouse.

The Active Enterprise Intelligence environment:

    Is responsive, agile, and capable of driving better, faster decisions that drive intelligent, and often immediate, actions. (Active)
    Provides a single view of the business, across appropriate business functions, and enables new operational users, processes, and applications. (Enterprise)
    Supports traditional strategic users and new operational users of the Enterprise Data Warehouse. Most importantly, it enables the linkage and alignment of operational systems, business processes and people with corporate goals so companies may execute on their strategies. (Intelligence)

###Active Data Warehousing
ADW is traditional Data Warehousing (EDW) with some active elements:

Active Load 

    Loading the database based on application requirements

Active Event 

    Activity or transaction identified by the application of a business rule

Active Access 

    Access the database in a mixed workload environment

Active Workload Management Dynamically manage a mixed workload environment

    • Performance - response time within seconds
    • Scalability
      – large amounts of detailed data
      – mixed workloads (tactical and strategic) for mission critical applications
      – concurrent users
    • Availability and Reliability - 7 x 24
    • Data Freshness - accurate, up-to-the-minute data, including access to ODS data

###The Data Warehouse
A data warehouse is a central, enterprise-wide database that contains information extracted from the operational systems (this is where the saying, “Load once, use many” comes from).

    Based on enterprise-wide model
    Can begin small but may grow large rapidly
    Populated by extraction/loading of data from operational systems
    Responds to users "what if" queries
    Minimizes data movement/synchronization
    Provides a single view of the business

###Data Marts
A data mart is a special purpose subset of data used by a particular department, function or application.

Data mart types:

    – Independent - created directly from operational systems to a separate physical data store
    – Logical - exists as a subset of existing data warehouse via Views
    – Dependent - created from data warehouse to a separate physical data store


